{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "plot_vocal_separation.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leodenale/VocalSeparation/blob/master/plot_vocal_separation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bycSl8fH8aye",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "[Referencia: Vocal Separation (libROSA)](http://librosa.github.io/librosa/auto_examples/plot_vocal_separation.html#sphx-glr-auto-examples-plot-vocal-separation-py)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZI3VHIRC9Az3",
        "colab_type": "text"
      },
      "source": [
        "**Mounting Google Drive in Google Colab**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIPIHFLI9El_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/mydrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KONWKVcg9Gyv",
        "colab_type": "text"
      },
      "source": [
        "**Navigating to project directory**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvNU73L49MNf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "65cac9b4-c334-4f16-e622-d3adf83e3079"
      },
      "source": [
        "cd .."
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEnRfY6m9ONP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qV2NQ5sj9QOX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "360cf997-18c4-4192-ad7c-ee188cdeb6ef"
      },
      "source": [
        "cd mydrive/My Drive/Colab Notebooks"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/mydrive/My Drive/Colab Notebooks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7umDml4h9TTB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/leodenale/VocalSeparation.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_LqcdYG9cEx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd VocalSeparation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-tb3v249e_A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnVgR-JL8FgI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IitgkwS8FgQ",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# Vocal separation\n",
        "\n",
        "\n",
        "This notebook demonstrates a simple technique for separating vocals (and\n",
        "other sporadic foreground signals) from accompanying instrumentation.\n",
        "\n",
        "This is based on the \"REPET-SIM\" method of `Rafii and Pardo, 2012\n",
        "<http://www.cs.northwestern.edu/~zra446/doc/Rafii-Pardo%20-%20Music-Voice%20Separation%20using%20the%20Similarity%20Matrix%20-%20ISMIR%202012.pdf>`_, but includes a couple of modifications and extensions:\n",
        "\n",
        "    - FFT windows overlap by 1/4, instead of 1/2\n",
        "    - Non-local filtering is converted into a soft mask by Wiener filtering.\n",
        "      This is similar in spirit to the soft-masking method used by `Fitzgerald, 2012\n",
        "      <http://arrow.dit.ie/cgi/viewcontent.cgi?article=1086&context=argcon>`_,\n",
        "      but is a bit more numerically stable in practice.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeCjgo5e8FgR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Code source: Brian McFee\n",
        "# License: ISC\n",
        "\n",
        "##################\n",
        "# Standard imports\n",
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa\n",
        "\n",
        "import librosa.display"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qn69B_D98FgU",
        "colab_type": "text"
      },
      "source": [
        "Load an example with vocals.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6o_--cH78FgV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y, sr = librosa.load('audio/Cheese_N_Pot-C_-_16_-_The_Raps_Well_Clean_Album_Version.mp3', duration=120)\n",
        "\n",
        "\n",
        "# And compute the spectrogram magnitude and phase\n",
        "S_full, phase = librosa.magphase(librosa.stft(y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qnQPxEP8FgY",
        "colab_type": "text"
      },
      "source": [
        "Plot a 5-second slice of the spectrum\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qE2dwTcM8FgZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "idx = slice(*librosa.time_to_frames([30, 35], sr=sr))\n",
        "plt.figure(figsize=(12, 4))\n",
        "librosa.display.specshow(librosa.amplitude_to_db(S_full[:, idx], ref=np.max),\n",
        "                         y_axis='log', x_axis='time', sr=sr)\n",
        "plt.colorbar()\n",
        "plt.tight_layout()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTCVxDV98Fgc",
        "colab_type": "text"
      },
      "source": [
        "The wiggly lines above are due to the vocal component.\n",
        "Our goal is to separate them from the accompanying\n",
        "instrumentation.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbyF1rUp8Fgd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We'll compare frames using cosine similarity, and aggregate similar frames\n",
        "# by taking their (per-frequency) median value.\n",
        "#\n",
        "# To avoid being biased by local continuity, we constrain similar frames to be\n",
        "# separated by at least 2 seconds.\n",
        "#\n",
        "# This suppresses sparse/non-repetetitive deviations from the average spectrum,\n",
        "# and works well to discard vocal elements.\n",
        "\n",
        "S_filter = librosa.decompose.nn_filter(S_full,\n",
        "                                       aggregate=np.median,\n",
        "                                       metric='cosine',\n",
        "                                       width=int(librosa.time_to_frames(2, sr=sr)))\n",
        "\n",
        "# The output of the filter shouldn't be greater than the input\n",
        "# if we assume signals are additive.  Taking the pointwise minimium\n",
        "# with the input spectrum forces this.\n",
        "S_filter = np.minimum(S_full, S_filter)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBWu6OCH8Fgg",
        "colab_type": "text"
      },
      "source": [
        "The raw filter output can be used as a mask,\n",
        "but it sounds better if we use soft-masking.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rJXlGSY8Fgh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We can also use a margin to reduce bleed between the vocals and instrumentation masks.\n",
        "# Note: the margins need not be equal for foreground and background separation\n",
        "margin_i, margin_v = 2, 10\n",
        "power = 2\n",
        "\n",
        "mask_i = librosa.util.softmask(S_filter,\n",
        "                               margin_i * (S_full - S_filter),\n",
        "                               power=power)\n",
        "\n",
        "mask_v = librosa.util.softmask(S_full - S_filter,\n",
        "                               margin_v * S_filter,\n",
        "                               power=power)\n",
        "\n",
        "# Once we have the masks, simply multiply them with the input spectrum\n",
        "# to separate the components\n",
        "\n",
        "S_foreground = mask_v * S_full\n",
        "S_background = mask_i * S_full"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evJ8ekL58Fgj",
        "colab_type": "text"
      },
      "source": [
        "Plot the same slice, but separated into its foreground and background\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGOeulXU8Fgk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sphinx_gallery_thumbnail_number = 2\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.subplot(3, 1, 1)\n",
        "librosa.display.specshow(librosa.amplitude_to_db(S_full[:, idx], ref=np.max),\n",
        "                         y_axis='log', sr=sr)\n",
        "plt.title('Full spectrum')\n",
        "plt.colorbar()\n",
        "\n",
        "plt.subplot(3, 1, 2)\n",
        "librosa.display.specshow(librosa.amplitude_to_db(S_background[:, idx], ref=np.max),\n",
        "                         y_axis='log', sr=sr)\n",
        "plt.title('Background')\n",
        "plt.colorbar()\n",
        "plt.subplot(3, 1, 3)\n",
        "librosa.display.specshow(librosa.amplitude_to_db(S_foreground[:, idx], ref=np.max),\n",
        "                         y_axis='log', x_axis='time', sr=sr)\n",
        "plt.title('Foreground')\n",
        "plt.colorbar()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}